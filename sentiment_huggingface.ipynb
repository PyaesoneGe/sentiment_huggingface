{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PyaesoneGe/sentiment_huggingface/blob/main/sentiment_huggingface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ruqK8H_EX-j",
        "outputId": "54223ba6-044f-4b6e-b777-a6277f614c2f"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM9GTsnZGMB0"
      },
      "source": [
        "\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUXtL0268-gF",
        "outputId": "39a8bbf9-cf25-48d2-93c4-bbaedaacbc89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "XYJgDHaM-Mti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjT86fYzF-Ji"
      },
      "source": [
        "train_data=pd.read_csv(\"/content/drive/MyDrive/twitter_training.csv\")\n",
        "test_data=pd.read_csv(\"/content/drive/MyDrive/twitter_validation.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-E5rEGisGbi0",
        "outputId": "cd257e4e-71ab-40b4-e18a-82a92f76a516"
      },
      "source": [
        "print(len(train_data))\n",
        "print(len(test_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74681\n",
            "999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.columns=['ID','company','sentiment','text']\n",
        "test_data.columns=['ID','company','sentiment','text']"
      ],
      "metadata": {
        "id": "2nTdPerL_D6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data[train_data['sentiment'] != \"Irrelevant\"]\n",
        "test_data = test_data[test_data['sentiment'] != \"Irrelevant\"]"
      ],
      "metadata": {
        "id": "Mq6zI9Kx_O9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data))\n",
        "print(len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WZXK9s_CsI-",
        "outputId": "adfcb60b-cf21-4f0f-d88c-a64254f05024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "61691\n",
            "828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_data = train_data[train_data['sentiment'] != \"Neutral\"]\n",
        "test_data = test_data[test_data['sentiment'] != \"Neutral\"]"
      ],
      "metadata": {
        "id": "1a2k1n6LCfaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data))\n",
        "print(len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRhQjLGLCuSY",
        "outputId": "1f729c13-f1ec-4053-9048-dd8ba59f39cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43373\n",
            "543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train=train_data\n",
        "test=test_data"
      ],
      "metadata": {
        "id": "UfmE6PBF_m58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train[\"text\"].isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmWCbu7t_9L5",
        "outputId": "759c6f82-2475-48c3-dcbe-973485116164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "361"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "Jt8sY0CmAFNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train[\"text\"].isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZqVcgpaAGoX",
        "outputId": "3095cb88-b1ae-4ac7-d7b7-cb9c38e63144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data))\n",
        "print(len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZujdD8DC6uO",
        "outputId": "42677e48-92ef-45c0-f3bf-821be111ea41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43012\n",
            "543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "ReN2-AcJAM6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import spacy\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOJl0HP8AYAF",
        "outputId": "ac0c93b8-6c16-4af3-e224-920e3fa85033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Remove_punctuation(A):\n",
        "  A['text'] = A['text'].str.replace('[^\\w\\s]','')\n",
        "\n",
        "\n",
        "def Remove_stopwords(A):\n",
        "  stopword = nltk.corpus.stopwords.words('english')\n",
        "  stop = stopwords.words('english')\n",
        "  A['text'] = A['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "  A.head(20)\n",
        "\n",
        "\n",
        "def lower_case(A):\n",
        "  A['text'] = A['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "\n",
        "\n",
        "def Lemmatization(A):\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  def space(comment):\n",
        "    doc = nlp(comment)\n",
        "    return \" \".join([token.lemma_ for token in doc])\n",
        "  A['text']= A['text'].apply(space)\n",
        "  A.head(20)\n",
        "\n",
        "def re_emoji(A):\n",
        "  def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "  A['text'] = A['text'].apply(lambda x: remove_emoji(x))"
      ],
      "metadata": {
        "id": "nNCFpB11Ai2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_clean(B):\n",
        "  lower_case(B)\n",
        "  Remove_punctuation(B)\n",
        "  Remove_stopwords(B)\n",
        "  re_emoji(B)\n",
        "  Lemmatization(B)"
      ],
      "metadata": {
        "id": "NkxCKZ5dAnGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_clean(train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvoN0DiKAoB7",
        "outputId": "f2535b22-eaa3-4903-f121-eb26977e6e11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-73-62b190642b57>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  A['text'] = A['text'].str.replace('[^\\w\\s]','')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_clean(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnvyKi4iGmmt",
        "outputId": "5bd19468-e4b6-4bcd-fc76-469b34aa988c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-73-62b190642b57>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  A['text'] = A['text'].str.replace('[^\\w\\s]','')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA0RCjScGesl"
      },
      "source": [
        "checkpoint = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['sentiment'] = train['sentiment'].replace(['Positive'], 1)\n",
        "train['sentiment'] = train['sentiment'].replace(['Negative'], 0)\n"
      ],
      "metadata": {
        "id": "MyG_skm5D-QM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test['sentiment'] = test['sentiment'].replace(['Positive'], 1)\n",
        "test['sentiment'] = test['sentiment'].replace(['Negative'], 0)\n"
      ],
      "metadata": {
        "id": "OQAgkKvIEEjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=list(train['text'])\n",
        "Y=list(test['text'])"
      ],
      "metadata": {
        "id": "YQBkV2nPEPya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_sentiment=list(train['sentiment'])\n",
        "Y_sentiment=list(test['sentiment'])"
      ],
      "metadata": {
        "id": "j3YwggYBEwPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU-6NeMwHN6t"
      },
      "source": [
        "train_encodings = tokenizer(X,\n",
        "                            truncation=True,\n",
        "                            padding=True,\n",
        "                            return_tensors='tf')\n",
        "test_encodings = tokenizer(Y,\n",
        "                            truncation=True,\n",
        "                            padding=True,\n",
        "                            return_tensors='tf')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imnUqYUhHxjh"
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(train_encodings),\n",
        "    X_sentiment\n",
        "))\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(test_encodings),\n",
        "    Y_sentiment\n",
        "))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQx-CuS4KLCC",
        "outputId": "30532a1a-87e5-46cf-a66f-868e3c42927a"
      },
      "source": [
        "model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-dx5E3zKW0e"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
        "    loss=SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy'],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtbjM57XK6Gb",
        "outputId": "9f0e5db1-a5c2-434c-e575-7e0fc3a5649b"
      },
      "source": [
        "model.fit(train_dataset.shuffle(100).batch(16),\n",
        "          epochs=10,\n",
        "          batch_size=16,\n",
        "          validation_data=test_dataset.shuffle(100).batch(16))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2689/2689 [==============================] - 847s 315ms/step - loss: 0.3327 - accuracy: 0.8606 - val_loss: 0.3231 - val_accuracy: 0.8987\n",
            "Epoch 2/10\n",
            "2689/2689 [==============================] - 842s 313ms/step - loss: 0.2047 - accuracy: 0.9218 - val_loss: 0.2247 - val_accuracy: 0.9190\n",
            "Epoch 3/10\n",
            "2689/2689 [==============================] - 842s 313ms/step - loss: 0.1208 - accuracy: 0.9532 - val_loss: 0.1443 - val_accuracy: 0.9576\n",
            "Epoch 4/10\n",
            "2689/2689 [==============================] - 842s 313ms/step - loss: 0.0850 - accuracy: 0.9660 - val_loss: 0.1553 - val_accuracy: 0.9595\n",
            "Epoch 5/10\n",
            "2689/2689 [==============================] - 842s 313ms/step - loss: 0.0686 - accuracy: 0.9722 - val_loss: 0.1108 - val_accuracy: 0.9687\n",
            "Epoch 6/10\n",
            "2689/2689 [==============================] - 841s 313ms/step - loss: 0.0576 - accuracy: 0.9744 - val_loss: 0.1178 - val_accuracy: 0.9687\n",
            "Epoch 7/10\n",
            "2689/2689 [==============================] - 842s 313ms/step - loss: 0.0493 - accuracy: 0.9778 - val_loss: 0.0861 - val_accuracy: 0.9779\n",
            "Epoch 8/10\n",
            "2689/2689 [==============================] - 844s 314ms/step - loss: 0.0479 - accuracy: 0.9778 - val_loss: 0.1336 - val_accuracy: 0.9669\n",
            "Epoch 9/10\n",
            "2689/2689 [==============================] - 842s 313ms/step - loss: 0.0421 - accuracy: 0.9794 - val_loss: 0.0980 - val_accuracy: 0.9761\n",
            "Epoch 10/10\n",
            "2689/2689 [==============================] - 842s 313ms/step - loss: 0.0440 - accuracy: 0.9799 - val_loss: 0.0863 - val_accuracy: 0.9742\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7c772e9eb400>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBkW92ZyU9yT"
      },
      "source": [
        "model.save_pretrained(\"/tmp/sentiment_custom_model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1X6b2jUXzBB"
      },
      "source": [
        "#### Load saved model and run predict function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATMCwBZBX8KB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1159942-93d0-4efe-8870-265345385958"
      },
      "source": [
        "loaded_model = TFAutoModelForSequenceClassification.from_pretrained(\"/tmp/sentiment_custom_model\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at /tmp/sentiment_custom_model were not used when initializing TFDistilBertForSequenceClassification: ['dropout_59']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at /tmp/sentiment_custom_model and are newly initialized: ['dropout_79']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A60AVunIZsdg"
      },
      "source": [
        "np.set_printoptions(formatter={'float_kind':'{:f}'.format})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guuqXzg5aJDS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3641c0bd-6950-4d53-c125-c2f0561989e8"
      },
      "source": [
        "test_sentence = \"happy\"\n",
        "test_sentence_sarcasm = \"Amphibious pitcher makes debut\"\n",
        "\n",
        "predict_input = tokenizer.encode(test_sentence,\n",
        "                                 truncation=True,\n",
        "                                 padding=True,\n",
        "                                 return_tensors=\"tf\")\n",
        "tf_output = loaded_model.predict(predict_input)[0]\n",
        "tf_prediction = tf.nn.softmax(tf_output, axis=1).numpy()[0]\n",
        "print(tf_prediction)\n",
        "\n",
        "predict_input_s = tokenizer.encode(test_sentence_sarcasm,\n",
        "                                   truncation=True,\n",
        "                                   padding=True,\n",
        "                                   return_tensors=\"tf\")\n",
        "tf_output_s = model.predict(predict_input_s)[0]\n",
        "tf_prediction_s = tf.nn.softmax(tf_output_s, axis=1).numpy()[0]\n",
        "print(tf_prediction_s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 5s 5s/step\n",
            "[0.347839 0.652161]\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "[0.013792 0.986208]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"/content/drive/MyDrive/model_save\")"
      ],
      "metadata": {
        "id": "DUq_xVTumY6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = TFAutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/model_save\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOLuMsrwmiN8",
        "outputId": "97043771-14b9-4066-d0d1-2eac1a6928a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at /content/drive/MyDrive/model_save were not used when initializing TFDistilBertForSequenceClassification: ['dropout_59']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/model_save and are newly initialized: ['dropout_119']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentence = \"you are \"\n",
        "test_sentence_sarcasm = \"Amphibious pitcher makes debut\"\n",
        "\n",
        "predict_input = tokenizer.encode(test_sentence,\n",
        "                                 truncation=True,\n",
        "                                 padding=True,\n",
        "                                 return_tensors=\"tf\")\n",
        "tf_output = loaded_model.predict(predict_input)[0]\n",
        "tf_prediction = tf.nn.softmax(tf_output, axis=1).numpy()[0]\n",
        "print(tf_prediction)\n",
        "\n",
        "predict_input_s = tokenizer.encode(test_sentence_sarcasm,\n",
        "                                   truncation=True,\n",
        "                                   padding=True,\n",
        "                                   return_tensors=\"tf\")\n",
        "tf_output_s = model.predict(predict_input_s)[0]\n",
        "tf_prediction_s = tf.nn.softmax(tf_output_s, axis=1).numpy()[0]\n",
        "print(tf_prediction_s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZwa6LKgmqJ4",
        "outputId": "aa38e44a-e5d9-4b83-d8c3-ae6aa8e75f29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7c759f8f7eb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 4s 4s/step\n",
            "[0.990549 0.009451]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "[0.013792 0.986208]\n"
          ]
        }
      ]
    }
  ]
}